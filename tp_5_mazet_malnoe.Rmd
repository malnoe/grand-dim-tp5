---
title: "***TP 5 - Compte rendu de groupe***"
author: "Matthias MAZET, Garance MALNOË"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
    number_sections: true
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
 \usepackage{mdframed}
documentclass: article
classoption: a4paper
geometry: margin = 1.5 cm
---


\
\
\

```{r, message=FALSE, warning=FALSE}
# Packages statistiques
library(glmnet)

# Packages de style
library(ggplot2)
library(ggpubr) 
library(GGally)
library(tidyverse)
library(knitr)
library(kableExtra)
```



\newpage


## *Préparation des données.*
```{r}
data <- read.csv("day.csv")
```

Pour simplifier les méthodes, nous supprimons la variable "dteday" qui est au format "chr". Nous supprimons aussi "casual" et "registered" qui, en les sommant, donne la valeur de la variable à prédire "cnt". Enfin, nous supprimons la variable "instant" qui correspond simplement à l'index de chaque observation. Nous vérifions ensuite les valeurs manquantes, la dimension des données et les valeurs aberrantes.
```{r}
# Nettoyage
data <- data[, -c(1, 2, 14, 15)] # Suppression de variables

# Résumés statistiques des variables
kable(
  summary(data[, 1:6], digits = 2), caption = "Résumé statistiques des 6 premières variables",
  format = "latex", booktabs = TRUE, escape = FALSE, align = "r"
) %>%
  kable_styling(
    latex_options = c("striped", "HOLD_position", "scale_down"), font_size = 9
  ) %>%
  row_spec(0, bold=TRUE)

kable(
  summary(data[, 7:12], digits = 2), caption = "Résumé statistiques des 6 dernières variables", 
  digit = 3, format = "latex", booktabs = TRUE, escape = FALSE, align = "r"
) %>%
  kable_styling(
    latex_options = c("striped", "HOLD_position", "scale_down"), font_size = 9
  ) %>%
  row_spec(0, bold=TRUE)
```

Il n'y a aucune valeurs manquantes (`sum(is.na(data))` = 0), aucune variables ne semblent avoir de valeurs aberrantes (d'après les résumés statistiques) et nous sommes dans un cas où (n = 731) > (p = 12) , avec n le nombre d'observations et p le nombre de variables. Aussi, la variable à prédire, "cnt", compte le nombre d'emprunts de vélos réalisés dans une journée. Nous pouvons donc bien appliquer une régression de Poisson pour modéliser une variable de comptage. Dans ce but, nous séparons les données en X les variables explicatives, et y la variable à prédire.
```{r}
# Format matriciel pour glmnet
X <- as.matrix(data[colnames(data) != "cnt"])
y <- as.matrix(data$cnt)
```
\

## *Estimation et stabilité de l'estimateur.*
Nous ajustons un modèle de Poisson via `glmnet`. Pour cela, nous précisons `family = "poisson"` dans les fonctions de `glmnet`. Nous conservons arbitrairement la valeur de `lambda.1se` obtenue par validation croisée.
```{r}
# Seed pour la reproductibilité
set.seed(5)

# Fit du modèle
lambda_1se <- cv.glmnet(x = X, y = y, alpha = 1, family = "poisson")$lambda.1se
mod_lasso <- glmnet(x = X, y = y, alpha = 1, lambda = lambda_1se, family = "poisson")
```
Nous obtenons une valeur de lambda.1se = `r round(lambda_1se, 3)`, et les variabbles sélectionnées avec les données de base et cette valeur sont : `r paste(colnames(data)[which(coef(mod_lasso) != 0)[-1] - 1], collapse = ", ")`.

Regardons maintenant la stabilité de sélection de variables sur 100 itérations. Pour chaque itération, nous regardons quelles variables sont sélectionnées au `lambda.1se` exhibé précédemment et nous stockons l'information dans une matrice.
```{r}
set.seed(5)

# Nombre d'itérations
n_it <- 100

# Matrices des variables sélectionnées à chaque itérations
mat_vars <- matrix(data = 0, ncol = ncol(X), nrow = n_it)
colnames(mat_vars) <- colnames(X)

# Itérations boostrap
for (i in 1:n_it) {
  # Individus bootstrap
  ind_al <- sample(1:nrow(data), size = nrow(data), replace = TRUE)
  X <- as.matrix(data[ind_al, colnames(data) != "cnt"])
  y <- data[ind_al, "cnt"]
  # Fit du modèle
  mod_lasso <- glmnet(x = X, y = y, alpha = 1, lambda = lambda_1se, family = "poisson")
  # Variables sélectionnées à lambda.1se
  mat_vars[i, which(coef(mod_lasso) != 0)[-1] - 1] <- 1
}
```

```{r hm1, fig.align="center", fig.width=6, fig.height=3.5, fig.cap="Stabilité à lambda.1se au fil des itérations"}
# Stabilité des variables
### Dataset de résultat au format long
df_lasso <- t(mat_vars) %>%
  as.data.frame() %>%
  mutate(variable = rownames(.)) %>%
  pivot_longer(cols = -variable, names_to = "iteration", values_to = "selected") %>%
  mutate(iteration = as.numeric(gsub("V", "", iteration)))
### Figure ggplot
ggplot(df_lasso, aes(x = iteration, y = variable, fill = selected)) +
  geom_tile() +
  scale_fill_gradientn(colours = c("white", "black"), limits = c(0, 1), name = "Sélection") +
  labs(x = "Itération", y = "Indices des variables") +
  theme_light() +
  theme(
    axis.text = element_text(size = 8),
    axis.line = element_line(colour = "grey"),
    panel.border = element_blank(),
    panel.grid = element_blank(),
    legend.title = element_text(size = 10, face = "bold"),
    legend.position = "right"
  )
```

```{r}
pourc_selection <- apply(mat_vars, FUN = mean, MARGIN = 2)

kable(
  t(pourc_selection), caption = "Fréquence de sélection de chaque variable", 
  format = "latex", booktabs = TRUE, escape = FALSE, align = "r"
) %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"), font_size = 9) %>%
  row_spec(0, bold=TRUE)
```

La figure précédente **(Fig. \@ref(fig:hm1))** présente les variables sélectionnées à chaque itération, avec 1 = variable sélectionnée et 0 sinon (la légende de couleur devrait être discrète mais ggplot ne l'accepte pas sur une heatmap). Nous pouvons constater que certaines variables ("yr" ou "season" par exemple) sont toujours sélectionnées, tandis que d'autres le sont aléatoirement suivant l'itération ("hum" ou "temp" par exemple). La variable "mnth" n'est à l'inverse jamais sélectionnée. La méthode présente donc une légère instabilité sur la sélection de variables, ce qui peut témoigner de multicolinéarité entre certaines variables (notamment celles sélectionnées quelquefois mais pas toutes).

Pour renforcer l'analyse, nous pouvons regarder la stabilité de sélection de variables le long du chemin de régularisation. 
```{r}
set.seed(5) 

# Noms des variables explicatives
vars <- colnames(data)[colnames(data) != "cnt"] 

# Grille de lambda commune à toutes les répétitions.
lambda_grid <- seq(1, 300, by = 0.25)

# Paramètres fixes
n_it <- 100
p <- length(vars)
L <- length(lambda_grid)
n <- nrow(data)

# Fonction pour récupérer les variables sélectionnées
get_support <- function(model) {
  as.matrix(coef(model))[-1, , drop = FALSE] != 0  # On enlève l'intercept
}

# Initialisation des vecteurs et matrices de résultats
path_lasso <- array(0, dim = c(p, L, n_it), dimnames = list(vars, lambda_grid, NULL))

for (r in 1:n_it) {
  # Ré-échantillonage
  ind_al <- sample(1:n, size = n, replace = TRUE)
  X <- as.matrix(data[ind_al, colnames(data) != "cnt"])
  y <- data[ind_al, "cnt"]
  # Lasso
  ### fit pour chaque lambda
  lasso_fit <- glmnet(x = X, y = y, alpha = 1, family = "poisson", lambda = lambda_grid)
  ### variables sélectionnées pour chaque fit
  path_lasso[, , r] <- get_support(lasso_fit)
}

# On compte pour chaque variable pour chaque le nombre moyen de fois où elle est incluse
stab_lasso <- apply(path_lasso, c(1,2), mean)
```

```{r hm2, fig.align="center", fig.width=6, fig.height=3.5, fig.cap="Stabilité sur le chemin de régularisation"}
# Transformations pour les visualisation
df_lasso <- as.data.frame(stab_lasso) %>%
  mutate(variable = rownames(.)) %>%
  pivot_longer(-variable, names_to = "lambda", values_to = "freq") %>%
  mutate(lambda = as.numeric(lambda))

# Visualisaiton avec ggplot
ggplot(df_lasso, aes(x = lambda, y = variable, fill = freq)) +
  geom_tile() +
  geom_vline(xintercept = lambda_1se, color="#b31e1e", linewidth = .9) +
  scale_fill_gradientn(
    colours = c("white", "black"), limits = c(0, 1), name = "Fréq. de sélection"
  ) +
  labs(x = "lambda", y = "Variable") +
  theme_light() +
  theme(
    axis.text = element_text(size = 8),
    axis.line = element_line(colour = "grey"),
    panel.border = element_blank(),
    panel.grid = element_blank(),
    legend.title = element_text(size = 10, face = "bold"),
    legend.position = "right"
  )
```
Cette figure **(Fig. \@ref(fig:hm2))** nous permet de constater que la valeur de `lambda.1se` exhibée avec les données initiales se généralise assez bien sur des données bootstrap. En effet, cette valeur (ligne rouge) se trouve dans une zone assez stable sur le chemin de régularisation : seules "windspeed", "weekday" et "holiday" sont en grises, et donc sélectionnées aléatoirement suivant l'itération.

\

## *Sélection post-inférence.*

  1. *Construction d'un intervalle de confiance.*






