---
title: "TP5 noté individuel"
author: "Garance Malnoë"
date: "`r Sys.Date()`"
output: pdf_document
---

Librairies
```{r,message=FALSE,echo=FALSE,warning=FALSE}
# Modèles
library(glmnet)
# Selective Inference
library(selectiveInference)
# Visualisations
library(ggplot2)
library(ggpubr)
library(GGally)
# Gestion des données
library(dplyr)
library(tidyr)
```

# Préparation des données

Importation du jeu de données
```{r}
day <- read.csv("day.csv") 
# A modifier avec votre path
```

Vérifiez les dimensions des données et assurez-vous qu’elles sont cohérentes avec le modèle.
```{r}
View(day)
```
Il est nécessaire d'enlever les variables "instant","dteday" car il s'agit de l'instance et de la date. On supprime également les colonnes "casual" et "registered" car leur somme donne la variable que l'on souhaite prédire "cnt".
```{r}
day <- day[,-c(1,2,14,15)]
```

Les modèles de régression de Poisson sont utilisés lorsque l'on souhaite modéliser des variables de comptage. La variable d'intérêt dans ce jeu de données, "cnt", compte le nombre d'emprunt de vélos réalisés dans une journée, le modèle de régression de Poisson est adapté.

Vérifions les données manquantes
```{r}
sum(is.na(day))
```
Il n'y en a pas.

```{r}
dim(day)
```
Le jeu de donénes est composé de 731 observations de 11 variables explicatives et de la variable "cnt" à expliquer.

Vérifions la présence de données aberrantes :
```{r}
summary(day)
```
Il ne semble pas y en avoir, les minimums et maximum font sens.

Nous séparons le jeu de données day en : y, les données à expliquer, et X les variables explicatives.
```{r}
y <- day[,12]
X <- day[,-12]

X <- as.matrix(X) # Transformation en matrice nécessaire pour glmnet.
```


# Estimation et stabilité de l’estimateur

Modèle de regression de Poisson avec régularisation Lasso
```{r}
# On fait une cross-validation pour choisir le paramètre lambda le + adapté
set.seed(1) # Reproductibilité
lasso_cv <- cv.glmnet(
  X, y,
  alpha = 1, # lasso donc alpha=1
  nfolds=10, # K = 10 folds
  family="poisson" # Pour avoir une modèle de poisson
)
lambda.min <- lasso_cv$lambda.min
lambda.1se <- lasso_cv$lambda.1se

# On récupère le modèle correspondant
lasso.min <- glmnet(X, y, alpha = 1, lambda = lambda.min, family="poisson")
lasso.1se <- glmnet(X, y, alpha = 1, lambda = lambda.1se, family="poisson")
```

```{r}
lambda.min
lambda.1se
```
Le lambda.min obtenu par la cross-validation est de 20.3787 et le lambda.1se est de 119.3585.


Stabilité de la sélection des variables

```{r}
set.seed(1) # Reproductibilité

# Noms des variables explicatives, pour les vecteurs de résultat
vars <- colnames(day)[colnames(day) != "cnt"] 

# Nombre de répétition pour le bootstrap, à prendre suffisamment grand.
n_rep <- 1000 

p <- length(vars)
n <- nrow(day)

# Fonction pour récupérer les variables sélectionnées
get_support <- function(model) {
  as.matrix(coef(model))[-1, , drop = FALSE] != 0  # enlève intercept
}

# Initialisation des vecteurs / matrices de résultats
path_lasso   <- array(0, dim = c(p, n_rep), dimnames = list(vars, NULL))

for (r in 1:n_rep) {
  # Ré-échantillonage
  set.seed(100 + r)
  idx <- sample(1:n,size=n,replace=TRUE)
  new_day <- day[idx, ]
  new_y <- new_day[,12]
  new_X <- new_day[,-12]
  new_X <- as.matrix(new_X) # Transformation en matrice nécessaire pour glmnet.
  
  # Lasso
  ## fit pour chaque lambda
  lasso_fit <- glmnet(new_X, new_y, alpha = 1, family="poisson", lambda = lambda.1se)
  ## variables sélectionnées pour chaque fit
  path_lasso[, r] <- get_support(lasso_fit)
}

# On compte pour chaque variable pour chaque 
#le nombre moyen de fois où elle est incluse
stab_lasso <- apply(path_lasso, c(1), mean)
```

```{r}
stab_lasso
```
Pour ce lambda = lambda.1se, 
- certaines variables sont instables (en se fixant un seuil à 5% d'écart à 0 ou 1) : holiday, weekday, workingday, temp, hum et windspeed. Ces variables sont parfois sélectionnées mais pas toujours.
- certaines variables sont stables : season, yr, weathersit et atemp. Soit elles sont toujours sélectionnées (valeur proche de 1), soit elles ne sont jamais sélectionnées (valeur proche de 0).

Nous pouvons également regarder ce qu'il se passe pour l'ensemble des lambda :
```{r}
set.seed(1) # Reproductibilité

vars <- colnames(day)[colnames(day) != "cnt"] # Noms des variables explicatives.

n_rep <- 100 # Nombre de répétition pour le bootstrap, 
#à prendre suffisamment grand.

# On définit une grille de lambda commune à toutes les répétitions, 
# à prendre suffisament fine.
lambda_grid <- seq(1, 300, by=0.25)

p <- length(vars)
L <- length(lambda_grid)
n <- nrow(day)

# Fonction pour récupérer les variables sélectionnées
get_support <- function(model) {
  as.matrix(coef(model))[-1, , drop = FALSE] != 0  # enlève intercept
}

# Initialisation des vecteurs / matrices de résultats
path_lasso   <- array(0, dim = c(p, L, n_rep), dimnames = list(vars, lambda_grid, NULL))
lam_1se_lasso <- matrix(0, p, n_rep, dimnames = list(vars, NULL))

for (r in 1:n_rep) {
  # Ré-échantillonage
  set.seed(100 + r)
  idx <- sample(1:n,size=n,replace=TRUE)
  new_day <- day[idx, ]
  new_y <- new_day[,12]
  new_X <- new_day[,-12]
  new_X <- as.matrix(new_X) # Transformation en matrice nécessaire pour glmnet.
  
  # Lasso
  ## fit pour chaque lambda
  lasso_fit <- glmnet(new_X, new_y, alpha = 1, family="poisson", lambda = lambda_grid)
  ## variables sélectionnées pour chaque fit
  path_lasso[, , r] <- get_support(lasso_fit)
}

# On compte pour chaque variable pour chaque le nombre moyen de fois où elle est incluse
stab_lasso <- apply(path_lasso, c(1,2), mean)
```

```{r}
# Transformations pour les visualisation
df_lasso <- as.data.frame(stab_lasso) %>%
  mutate(variable = rownames(.)) %>%
  pivot_longer(-variable, names_to = "lambda", values_to = "freq") %>%
  mutate(lambda = as.numeric(lambda))

# Visualisaiton avec ggplot
ggplot(df_lasso, aes(x = lambda, y = variable, fill = freq)) +
  geom_tile() +
  geom_vline(xintercept = lambda.1se, color="indianred") +
  scale_fill_gradient(low = "white", high = "black") +
  labs(title = "Stabilité LASSO", x = "lambda", y = "variable")

```
La barre rouge correspond au lambda.1se obtenu précédement sur nos données originales (lambda.1se = 119.3585).

# Sélection post-inférence

## Construction d'un intervalle de confiance
```{r}
coefs.1se <- get_support(lasso.1se)
coefs.1se
```
Les coefficients sélectionnés par LASSO sur les données originales avec lambda = lambda.1se sont :
season, yr, holiday, weekday, weathsit, temp, atemp et windspeed.

Construisons le modèle de régression de poisson avec ces variables uniquement :
```{r}
y <- day[, 12]
X_bis <- day[, -c(3,6,10,12)]

# Régression de poisson correspondante
model_poiss <- glm(y ~ . , data = X_bis, family = poisson)

# Esimateur de beta
model_poiss$coefficients
```

On peut alors construire des intervalles de confiance pour tous les beta :

```{r}
# Coefficients beta
beta_true <- numeric(ncol(X_bis) + 1)
names(beta_true) <- c("(Intercept)", colnames(X_bis))
beta_true[names(coef(model_poiss))] <- coef(model_poiss)

# Ecarts-type
se <- summary(model_poiss)$coefficients[, 2]

# Calcul des bornes supérieure et inférieure
borne.inf <- beta_true - qnorm(0.975)*se/sqrt(n)
borne.sup <- beta_true + qnorm(0.975)*se/sqrt(n)

# Résultat
data.frame(borne.inf=borne.inf,borne.sup=borne.sup)
```

## Evaluation du niveau empirique
On a vu en cours que : 
$$
\lambda_i = \mathbb{E}[Y_i|X_i] = exp(x_i^T\hat\beta)
$$

```{r}
# Nombre de répétition
nrep <- 100

# Compteurs pour la couverture
compteur_couverture <- setNames(numeric(length(beta_true)), names(beta_true))
nbr_intervales     <- setNames(numeric(length(beta_true)), names(beta_true))

# On récupère les lambda_i pour les n individus
lambda_hat <- predict(model_poiss, type = "response") # pred pour les données originale taille n

for(i in 1:nrep){
  # On simule de nouvelles valeurs pour cnt suivant le modèle, avec lambda_i = l'intensité pour l'obs i = lambda_hat[i]
  set.seed(100+i)
  y_sim <- rpois(n, lambda = lambda_hat)
  # Ajustement d'un modèle LASSO avec lambda = lambda.1se
  cv_i <- cv.glmnet(as.matrix(X_bis),y_sim,family="poisson")
  lambda_i <- cv_i$lambda.1se
  
  # Récupération du support correspondant
  coef_i <- coef(cv_i, s=lambda_i)
  index_col_select <- which(as.vector(coef_i[-1,1])!=0)
  
  # Calcul du modèle de poisson, récupération du beta.hat et des intervalles de confiance
  X_act_i <- X_bis[,index_col_select,drop=FALSE]
  model_poiss_i <- glm(y_sim ~ . , data = X_act_i, family = poisson)
  
  # Récupération du beta et se pour les coefficients actifs
  beta_i <- numeric(ncol(X_act_i) + 1)
  names(beta_i) <- c("(Intercept)", colnames(X_act_i))
  beta_i[names(coef(model_poiss_i))] <- coef(model_poiss_i)
  se <- summary(model_poiss_i)$coefficients[, 2]
  borne.inf_i <- beta_i - qnorm(0.975)*se/sqrt(n)
  borne.sup_i <- beta_i + qnorm(0.975)*se/sqrt(n)
  # Évaluation si coefficient vrai est dans intervalle de confiance
  for(name in names(borne.inf_i)){
    beta_true_j <- beta_true[name]
    inf <- borne.inf_i[name]
    sup <- borne.sup_i[name]
    nbr_intervales[name] <- nbr_intervales[name] + 1 # On augmente le compteur de 1
    if (beta_true_j >= inf && beta_true_j <= sup) {
      compteur_couverture[name] <- compteur_couverture[name] + 1
    }
  }
}

niveau_empirique <- compteur_couverture / nbr_intervales
compteur_couverture
nbr_intervales
niveau_empirique
mean(niveau_empirique)
```
Nous obtenons un niveau de confiance moyen de 7% contre les 100(1-alpha) = 95% qui seraient attendus. Cela est du au fait que nous effectuions une inférence naïve après avoir déjà fait une sélection : nous avons sélectionné les variables actives avec LASSO (qui dépend des données) puis nous faisons une seconde inférence naïve classique qui suppose que le modèle est fixé avant de regarder les données (or on les a déjà vues avec LASSO pour choisir le modèle). Cela donnent lieu à des intervalles de confiance très très ressérés, trop optimiste dans lequel la véritable valeur ne se trouve pas.
Le modèle étant choisi via les données, les intervalles de confiance classiques sont fortement ressérés.
Il est donc nécessaire d'opter pour une approche afin d'obtenir des intervalles de confiance : data-splitting (problème c'est qu'on perd une partie des données) ou selectiveInference que nous avons vu en cours.








