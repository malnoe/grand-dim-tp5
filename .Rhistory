# Modèles
library(glmnet)
# Selective Inference
library(selectiveInference)
# Visualisations
library(ggplot2)
library(ggpubr)
library(GGally)
# Gestion des données
library(dplyr)
library(tidyr)
day <- read.csv("day.csv")
# A modifier avec votre path
View(day)
day <- day[,-c(1,2,14,15)]
sum(is.na(day))
dim(day)
summary(day)
y <- day[,12]
X <- day[,-12]
X <- as.matrix(X) # Transformation en matrice nécessaire pour glmnet.
# On fait une cross-validation pour choisir le paramètre lambda le + adapté
set.seed(1) # Reproductibilité
lasso_cv <- cv.glmnet(
X, y,
alpha = 1, # lasso donc alpha=1
nfolds=10, # K = 10 folds
family="poisson" # Pour avoir une modèle de poisson
)
lambda.min <- lasso_cv$lambda.min
lambda.1se <- lasso_cv$lambda.1se
# On récupère le modèle correspondant
lasso.min <- glmnet(X, y, alpha = 1, lambda = lambda.min, family="poisson")
lasso.1se <- glmnet(X, y, alpha = 1, lambda = lambda.1se, family="poisson")
lambda.min
lambda.1se
set.seed(1) # Reproductibilité
# Noms des variables explicatives, pour les vecteurs de résultat
vars <- colnames(day)[colnames(day) != "cnt"]
# Nombre de répétition pour le bootstrap, à prendre suffisamment grand.
n_rep <- 1000
p <- length(vars)
n <- nrow(day)
# Fonction pour récupérer les variables sélectionnées
get_support <- function(model) {
as.matrix(coef(model))[-1, , drop = FALSE] != 0  # enlève intercept
}
# Initialisation des vecteurs / matrices de résultats
path_lasso   <- array(0, dim = c(p, n_rep), dimnames = list(vars, NULL))
for (r in 1:n_rep) {
# Ré-échantillonage
set.seed(100 + r)
idx <- sample(1:n,size=n,replace=TRUE)
new_day <- day[idx, ]
new_y <- new_day[,12]
new_X <- new_day[,-12]
new_X <- as.matrix(new_X) # Transformation en matrice nécessaire pour glmnet.
# Lasso
## fit pour chaque lambda
lasso_fit <- glmnet(new_X, new_y, alpha = 1, family="poisson", lambda = lambda.1se)
## variables sélectionnées pour chaque fit
path_lasso[, r] <- get_support(lasso_fit)
}
# On compte pour chaque variable pour chaque
#le nombre moyen de fois où elle est incluse
stab_lasso <- apply(path_lasso, c(1), mean)
stab_lasso
set.seed(1) # Reproductibilité
vars <- colnames(day)[colnames(day) != "cnt"] # Noms des variables explicatives.
n_rep <- 100 # Nombre de répétition pour le bootstrap,
#à prendre suffisamment grand.
# On définit une grille de lambda commune à toutes les répétitions,
# à prendre suffisament fine.
lambda_grid <- seq(1, 300, by=0.25)
p <- length(vars)
L <- length(lambda_grid)
n <- nrow(day)
# Fonction pour récupérer les variables sélectionnées
get_support <- function(model) {
as.matrix(coef(model))[-1, , drop = FALSE] != 0  # enlève intercept
}
# Initialisation des vecteurs / matrices de résultats
path_lasso   <- array(0, dim = c(p, L, n_rep), dimnames = list(vars, lambda_grid, NULL))
lam_1se_lasso <- matrix(0, p, n_rep, dimnames = list(vars, NULL))
for (r in 1:n_rep) {
# Ré-échantillonage
set.seed(100 + r)
idx <- sample(1:n,size=n,replace=TRUE)
new_day <- day[idx, ]
new_y <- new_day[,12]
new_X <- new_day[,-12]
new_X <- as.matrix(new_X) # Transformation en matrice nécessaire pour glmnet.
# Lasso
## fit pour chaque lambda
lasso_fit <- glmnet(new_X, new_y, alpha = 1, family="poisson", lambda = lambda_grid)
## variables sélectionnées pour chaque fit
path_lasso[, , r] <- get_support(lasso_fit)
}
# On compte pour chaque variable pour chaque le nombre moyen de fois où elle est incluse
stab_lasso <- apply(path_lasso, c(1,2), mean)
# Transformations pour les visualisation
df_lasso <- as.data.frame(stab_lasso) %>%
mutate(variable = rownames(.)) %>%
pivot_longer(-variable, names_to = "lambda", values_to = "freq") %>%
mutate(lambda = as.numeric(lambda))
# Visualisaiton avec ggplot
ggplot(df_lasso, aes(x = lambda, y = variable, fill = freq)) +
geom_tile() +
geom_vline(xintercept = lambda.1se, color="indianred") +
scale_fill_gradient(low = "white", high = "black") +
labs(title = "Stabilité LASSO", x = "lambda", y = "variable")
coefs.1se <- get_support(lasso.1se)
coefs.1se
# Jeu de données avec variables sélectionnées
y <- day[,12]
X_bis <- day[,-c(3,6,10,12)] # on enlève mnth, workingday, hum qui n'ont pas été sélectionnées et cnt qu'on veut prédire.
# Régression de poisson correspondante
model_poiss <- glm(y ~ ., data = X_bis, family = poisson)
summary(model_poiss)
# Esimateur de beta
model_poiss$coefficients
confint(model_poiss)
set.seed(1) # Reproductibilité
# Noms des variables explicatives, pour les vecteurs de résultat
vars <- colnames(day)[colnames(day) != "cnt"]
# Nombre de répétition pour le bootstrap, à prendre suffisamment grand.
n_rep <- 1000
p <- length(vars)
n <- nrow(day)
# Fonction pour récupérer les variables sélectionnées
get_support <- function(model) {
as.matrix(coef(model))[-1, , drop = FALSE] != 0  # enlève intercept
}
# Initialisation des vecteurs / matrices de résultats
path_lasso   <- array(0, dim = c(p, n_rep), dimnames = list(vars, NULL))
for (r in 1:n_rep) {
# Ré-échantillonage
set.seed(100 + r)
idx <- sample(1:n,size=n,replace=TRUE)
new_day <- day[idx, ]
new_y <- new_day[,12]
new_X <- new_day[,-12]
new_X <- as.matrix(new_X) # Transformation en matrice nécessaire pour glmnet.
# Lasso
## fit pour chaque lambda
lasso_fit <- glmnet(new_X, new_y, alpha = 1, family="poisson", lambda = lambda.1se)
## variables sélectionnées pour chaque fit
path_lasso[, r] <- get_support(lasso_fit)
}
# On compte pour chaque variable pour chaque
#le nombre moyen de fois où elle est incluse
stab_lasso <- apply(path_lasso, c(1), mean)
stab_lasso
# Jeu de données avec variables sélectionnées
y <- day[,12]
X_bis <- day[,-c(3,6,10,12)] # on enlève mnth, workingday, hum qui n'ont pas été sélectionnées et cnt qu'on veut prédire.
# Régression de poisson correspondante
model_poiss <- glm(y ~ ., data = X_bis, family = poisson)
# Esimateur de beta
model_poiss$coefficients
model_poiss$effects
summary(model_poiss)
View(model_poiss)
summary(model_poiss)$coefficients[, 2]
se <- summary(model_poiss)$coefficients[, 2]
se <- summary(model_poiss)$coefficients[, 2]
beta <- model_poiss$coefficients
se <- summary(model_poiss)$coefficients[, 2]
borne.inf <- beta - qnorm(0.975)*se/sqrt(n)
borne.sup <- beta + qnorm(0.975)*se/sqrt(n)
beta <- model_poiss$coefficients
se <- summary(model_poiss)$coefficients[, 2]
borne.inf <- beta - qnorm(0.975)*se/sqrt(n)
borne.sup <- beta + qnorm(0.975)*se/sqrt(n)
borne.inf
borne.sup
# On récupère les beta et les écart-types
beta <- model_poiss$coefficients
se <- summary(model_poiss)$coefficients[, 2]
# Calcul des bornes supérieure et inférieure
borne.inf <- beta - qnorm(0.975)*se/sqrt(n)
borne.sup <- beta + qnorm(0.975)*se/sqrt(n)
data.frame(borne.inf=borne.inf,borne.sup=borne.sup)
n
?generate
generate(model_poiss)
se
